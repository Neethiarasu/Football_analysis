{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after merging: (57057, 90)\n",
      "Data shape after adding injury columns: (57057, 90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neethiarasu\\AppData\\Local\\Temp\\ipykernel_17340\\3686153500.py:84: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  csv_data[column] = csv_data[column].fillna(csv_data[column].mode()[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after handling missing values: (57057, 90)\n",
      "Data shape after handling missing values: (57057, 90)\n",
      "Scaling 45 numerical features for 57057 samples.\n",
      "Data shape after encoding and scaling: (57057, 90)\n",
      "Enhanced dataset saved successfully at: D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/processed/merged_data.csv\n",
      "Train and test datasets saved successfully in: D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the raw CSV datasets.\"\"\"\n",
    "    player_stats_path = 'D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/raw/player_statistics.csv'\n",
    "    match_events_path = 'D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/raw/match_events.csv'\n",
    "    positional_data_path = 'D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/raw/positional_data.csv'\n",
    "    biomechanical_data_path = 'D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/raw/biomechanical_data.csv'\n",
    "\n",
    "    player_stats = pd.read_csv(player_stats_path)\n",
    "    match_events = pd.read_csv(match_events_path)\n",
    "    positional_data = pd.read_csv(positional_data_path)\n",
    "    biomechanical_data = pd.read_csv(biomechanical_data_path)\n",
    "    \n",
    "    return player_stats, match_events, positional_data, biomechanical_data\n",
    "\n",
    "def merge_datasets(player_stats, match_events, biomechanical_data):\n",
    "    \"\"\"Merge the datasets based on common columns.\"\"\"\n",
    "    player_stats['name'] = player_stats['name'].astype(str).str.lower().str.strip()\n",
    "    biomechanical_data['Subject'] = biomechanical_data['Subject'].astype(str)\n",
    "    \n",
    "    # Example mapping of Subject to player names\n",
    "    subject_to_name = {\n",
    "        '1': 'manuel neuer',\n",
    "        '2': 'yann sommer',\n",
    "        '3': 'sven ulreich',\n",
    "        '4': 'johannes schenk',\n",
    "        '5': 'matthijs de ligt',\n",
    "        '6': 'dayot upamecano',\n",
    "        '7': 'lucas hernández',\n",
    "        '8': 'alphonso davies',\n",
    "        '9': 'daley blind',\n",
    "        '10': 'joão cancelo',\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "    \n",
    "    biomechanical_data['name'] = biomechanical_data['Subject'].map(subject_to_name).str.lower().str.strip()\n",
    "\n",
    "    # Merge player statistics with biomechanical data based on player name\n",
    "    merged_data = pd.merge(player_stats, biomechanical_data, on='name', how='left')\n",
    "    \n",
    "    # Merge the result with match events based on the club name and match date\n",
    "    merged_data = pd.merge(merged_data, match_events, left_on='club', right_on='HOME_TEAM_NAME', how='left', suffixes=('_player', '_match'))\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "def add_injury_columns(csv_data):\n",
    "    \"\"\"Add injury-related columns.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    csv_data['Injury'] = np.random.choice([0, 1], size=len(csv_data), p=[0.8, 0.2])\n",
    "\n",
    "    injury_locations = ['Knee', 'Ankle', 'Hamstring', 'Shoulder', np.nan]\n",
    "    csv_data['InjuryLoc'] = np.where(csv_data['Injury'] == 1, np.random.choice(injury_locations, size=len(csv_data)), np.nan)\n",
    "\n",
    "    dates = pd.date_range(start='2020-01-01', end='2023-01-01')\n",
    "    csv_data['InjuryOnDate'] = np.where(csv_data['Injury'] == 1, np.random.choice(dates, size=len(csv_data)), pd.NaT)\n",
    "\n",
    "    return csv_data\n",
    "\n",
    "def handle_missing_values(csv_data):\n",
    "    \"\"\"Handle missing values in the dataset.\"\"\"\n",
    "    # Fill missing values for InjuryLoc with 'None'\n",
    "    csv_data['InjuryLoc'] = csv_data['InjuryLoc'].fillna('None')\n",
    "\n",
    "    # Fill NaNs in numerical columns with the median value\n",
    "    numerical_columns = csv_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        if csv_data[column].isna().sum() > 0:\n",
    "            csv_data[column] = csv_data[column].fillna(csv_data[column].median())\n",
    "\n",
    "    # Fill NaNs in categorical columns with the mode\n",
    "    categorical_columns = csv_data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if csv_data[column].isna().sum() > 0:\n",
    "            if csv_data[column].dropna().empty:\n",
    "                # If the entire column is NaN, fill with a placeholder like 'Unknown'\n",
    "                csv_data[column] = csv_data[column].fillna('Unknown')\n",
    "            else:\n",
    "                # Fill with mode if the column has valid entries\n",
    "                csv_data[column] = csv_data[column].fillna(csv_data[column].mode()[0])\n",
    "\n",
    "    # Optionally, drop columns that are still entirely NaN\n",
    "    csv_data = csv_data.dropna(axis=1, how='all')\n",
    "\n",
    "    # Print the shape after handling missing values\n",
    "    print(f\"Data shape after handling missing values: {csv_data.shape}\")\n",
    "\n",
    "    return csv_data\n",
    "\n",
    "def encode_and_scale_features(csv_data):\n",
    "    \"\"\"Encode categorical variables and scale numerical features.\"\"\"\n",
    "    # Encoding categorical features\n",
    "    categorical_features = ['club', 'position', 'InjuryLoc']\n",
    "    for feature in categorical_features:\n",
    "        encoder = LabelEncoder()\n",
    "        csv_data[feature] = encoder.fit_transform(csv_data[feature].astype(str))\n",
    "    \n",
    "    # Scaling numerical features\n",
    "    numerical_features = csv_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    if len(csv_data) > 0 and len(numerical_features) > 0:\n",
    "        print(f\"Scaling {len(numerical_features)} numerical features for {len(csv_data)} samples.\")\n",
    "        scaler = StandardScaler()\n",
    "        csv_data[numerical_features] = scaler.fit_transform(csv_data[numerical_features])\n",
    "    else:\n",
    "        print(\"No data available for scaling.\")\n",
    "    \n",
    "    return csv_data\n",
    "\n",
    "def save_processed_data(csv_data, output_path):\n",
    "    \"\"\"Save the processed dataset to a CSV file.\"\"\"\n",
    "    csv_data.to_csv(output_path, index=False)\n",
    "    print(f\"Enhanced dataset saved successfully at: {output_path}\")\n",
    "\n",
    "def split_and_save_data(csv_data, output_dir):\n",
    "    \"\"\"Split the data into train and test sets and save them to CSV files.\"\"\"\n",
    "    X = csv_data.drop(columns=['Injury'])\n",
    "    y = csv_data['Injury']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Save the split datasets\n",
    "    X_train.to_csv(f'{output_dir}/X_train.csv', index=False)\n",
    "    X_test.to_csv(f'{output_dir}/X_test.csv', index=False)\n",
    "    y_train.to_csv(f'{output_dir}/y_train.csv', index=False)\n",
    "    y_test.to_csv(f'{output_dir}/y_test.csv', index=False)\n",
    "    \n",
    "    print(f\"Train and test datasets saved successfully in: {output_dir}\")\n",
    "\n",
    "def main():\n",
    "    # Specify the output file path\n",
    "    output_dir = 'D:/Data science classes slides pdf/Football_analysis/football_analytics_injury_prevention/processed'\n",
    "    merged_data_path = f'{output_dir}/merged_data.csv'\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Step 1: Load the data\n",
    "    player_stats, match_events, positional_data, biomechanical_data = load_data()\n",
    "    \n",
    "    # Step 2: Merge the datasets\n",
    "    merged_data = merge_datasets(player_stats, match_events, biomechanical_data)\n",
    "    print(f\"Data shape after merging: {merged_data.shape}\")\n",
    "    \n",
    "    # Step 3: Add injury-related columns\n",
    "    merged_data = add_injury_columns(merged_data)\n",
    "    print(f\"Data shape after adding injury columns: {merged_data.shape}\")\n",
    "    \n",
    "    # Step 4: Handle missing values\n",
    "    merged_data = handle_missing_values(merged_data)\n",
    "    print(f\"Data shape after handling missing values: {merged_data.shape}\")\n",
    "    \n",
    "    # Step 5: Encode categorical variables and scale numerical features\n",
    "    merged_data = encode_and_scale_features(merged_data)\n",
    "    print(f\"Data shape after encoding and scaling: {merged_data.shape}\")\n",
    "    \n",
    "    # Step 6: Save the processed data\n",
    "    save_processed_data(merged_data, merged_data_path)\n",
    "    \n",
    "    # Step 7: Split the data into train and test sets and save them\n",
    "    split_and_save_data(merged_data, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  Volume  Pace RFSI25 LFSI25 Injury InjuryLoc InjuryOnDate\n",
      "0      Manuel Neuer       0   NaN    NaN    NaN    NaN       NaN          NaN\n",
      "1       Yann Sommer       0   NaN    NaN    NaN    NaN       NaN          NaN\n",
      "2      Sven Ulreich       0   NaN    NaN    NaN    NaN       NaN          NaN\n",
      "3   Johannes Schenk       0   NaN    NaN    NaN    NaN       NaN          NaN\n",
      "4  Matthijs de Ligt       0   NaN    NaN    NaN    NaN       NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "print(merged_data[['name', 'Volume', 'Pace', 'RFSI25', 'LFSI25', 'Injury', 'InjuryLoc', 'InjuryOnDate']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject                  FileName  Age  Height  Mass Gender Dominance  \\\n",
      "0        1         RBDS001static.txt   22   181.0  62.0      M         R   \n",
      "1        1  RBDS001runT25markers.txt   22   181.0  62.0      M         R   \n",
      "2        1   RBDS001runT25forces.txt   22   181.0  62.0      M         R   \n",
      "3        1  RBDS001runT35markers.txt   22   181.0  62.0      M         R   \n",
      "4        1   RBDS001runT35forces.txt   22   181.0  62.0      M         R   \n",
      "\n",
      "         Level  Experience  SessionsPerWk  ...  ROber  LOber  RHIPABD  \\\n",
      "0  Competitive           4              3  ...     43     40     16.8   \n",
      "1  Competitive           4              3  ...     43     40     16.8   \n",
      "2  Competitive           4              3  ...     43     40     16.8   \n",
      "3  Competitive           4              3  ...     43     40     16.8   \n",
      "4  Competitive           4              3  ...     43     40     16.8   \n",
      "\n",
      "   LHIPABD  RHIPEXT  LHIPEXT    RHIPER LHIPER     RHIPIR  name  \n",
      "0   21.575   16.575   21.675  9.666667   7.25  10.966667   NaN  \n",
      "1   21.575   16.575   21.675  9.666667   7.25  10.966667   NaN  \n",
      "2   21.575   16.575   21.675  9.666667   7.25  10.966667   NaN  \n",
      "3   21.575   16.575   21.675  9.666667   7.25  10.966667   NaN  \n",
      "4   21.575   16.575   21.675  9.666667   7.25  10.966667   NaN  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28]\n"
     ]
    }
   ],
   "source": [
    "print(biomechanical_data.head())  # Check if the biomechanical data has values\n",
    "print(biomechanical_data['Subject'].unique())  # Verify unique subjects in biomechanical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example subject-to-name mapping\n",
    "subject_to_name = {\n",
    "    '1': 'manuel neuer',\n",
    "    '2': 'yann sommer',\n",
    "    '3': 'sven ulreich',\n",
    "    '4': 'johannes schenk',\n",
    "    '5': 'matthijs de ligt',\n",
    "    '6': 'dayot upamecano',\n",
    "    '7': 'lucas hernández',\n",
    "    '8': 'alphonso davies',\n",
    "    '9': 'daley blind',\n",
    "    '10': 'joão cancelo',\n",
    "    # Ensure all subjects are mapped here\n",
    "    # ...\n",
    "}\n",
    "\n",
    "biomechanical_data['name'] = biomechanical_data['Subject'].map(subject_to_name).str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(player_stats, biomechanical_data, on='name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name Volume  Pace RFSI25 LFSI25\n",
      "0      Manuel Neuer    NaN   NaN    NaN    NaN\n",
      "1       Yann Sommer    NaN   NaN    NaN    NaN\n",
      "2      Sven Ulreich    NaN   NaN    NaN    NaN\n",
      "3   Johannes Schenk    NaN   NaN    NaN    NaN\n",
      "4  Matthijs de Ligt    NaN   NaN    NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "print(merged_data[['name', 'Volume', 'Pace', 'RFSI25', 'LFSI25']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28]\n",
      "['Manuel Neuer' 'Yann Sommer' 'Sven Ulreich' 'Johannes Schenk'\n",
      " 'Matthijs de Ligt' 'Dayot Upamecano' 'Lucas Hernández' 'Alphonso Davies'\n",
      " 'Daley Blind' 'João Cancelo' 'Benjamin Pavard' 'Noussair Mazraoui'\n",
      " 'Josip Stanisic' 'Bouna Sarr' 'Joshua Kimmich' 'Leon Goretzka'\n",
      " 'Ryan Gravenberch' 'Jamal Musiala' 'Paul Wanner' 'Arijon Ibrahimovic'\n",
      " 'Kingsley Coman' 'Sadio Mané' 'Leroy Sané' 'Serge Gnabry' 'Thomas Müller'\n",
      " 'Mathys Tel' 'Eric Maxim Choupo-Moting' 'Gregor Kobel' 'Marcel Lotka'\n",
      " 'Alexander Meyer' 'Luca Unbehaun' 'Nico Schlotterbeck' 'Niklas Süle'\n",
      " 'Mats Hummels' 'Soumaïla Coulibaly' 'Antonios Papadopoulos'\n",
      " 'Raphaël Guerreiro' 'Tom Rothe' 'Nico Schulz' 'Julian Ryerson'\n",
      " 'Marius Wolf' 'Thomas Meunier' 'Mateu Morey Bauzà' 'Felix Passlack'\n",
      " 'Salih Özcan' 'Emre Can' 'Abdoulaye Kamara' 'Jude Bellingham'\n",
      " 'Mahmoud Dahoud' 'Julian Brandt' 'Giovanni Reyna' 'Marco Reus'\n",
      " 'Göktan Gürpüz' 'Karim Adeyemi' 'Jamie Bynoe-Gittens' 'Donyell Malen'\n",
      " 'Julien Duranville' 'Sébastien Haller' 'Youssoufa Moukoko'\n",
      " 'Anthony Modeste' 'Péter Gulácsi' 'Janis Blaswich' 'Örjan Nyland'\n",
      " 'Jonas Nickisch' 'Timo Schlieck' 'Oskar Preil' 'Josko Gvardiol'\n",
      " 'Mohamed Simakan' 'Abdou Diallo' 'Willi Orbán' 'David Raum'\n",
      " 'Marcel Halstenberg' 'Sanoussy Ba' 'Benjamin Henrichs'\n",
      " 'Lukas Klostermann' 'Konrad Laimer' 'Xaver Schlager' 'Amadou Haidara'\n",
      " 'Kevin Kampl' 'Dani Olmo' 'Dominik Szoboszlai' 'Emil Forsberg'\n",
      " 'Caden Clark' 'Christopher Nkunku' 'Timo Werner' 'André Silva'\n",
      " 'Yussuf Poulsen' 'Lukas Hradecky' 'Patrick Pentz' 'Andrey Lunev'\n",
      " 'Niklas Lomb' 'Edmond Tapsoba' 'Piero Hincapié' 'Jonathan Tah'\n",
      " 'Odilon Kossounou' 'Mitchel Bakker' 'Daley Sinkgraven' 'Jeremie Frimpong'\n",
      " 'Timothy Fosu-Mensah' 'Robert Andrich' 'Noah Mbamba' 'Ayman Azhil'\n",
      " 'Joshua Eze' 'Exequiel Palacios' 'Kerem Demirbay' 'Nadiem Amiri'\n",
      " 'Florian Wirtz' 'Callum Hudson-Odoi' 'Amine Adli' 'Moussa Diaby'\n",
      " 'Karim Bellarabi' 'Patrik Schick' 'Adam Hlozek' 'Sardar Azmoun'\n",
      " 'Kevin Trapp' 'Diant Ramaj' 'Jens Grahl' 'Simon Simoni' 'Evan Ndicka'\n",
      " 'Tuta' 'Hrvoje Smolcic' 'Almamy Touré' 'Makoto Hasebe' 'Philipp Max'\n",
      " 'Christopher Lenz' 'Jan Schröder' 'Aurélio Buta' 'Timothy Chandler'\n",
      " 'Kristijan Jakic' 'Djibril Sow' 'Sebastian Rode' 'Marcel Wenig'\n",
      " 'Mehdi Loune' 'Junior Dina Ebimbe' 'Daichi Kamada' 'Jesper Lindström'\n",
      " 'Mario Götze' 'Paxten Aaronson' 'Faride Alidou' 'Ansgar Knauff'\n",
      " 'Randal Kolo Muani' 'Rafael Borré' 'Lucas Alario' 'Nacho Ferri'\n",
      " 'Jonas Omlin' 'Jan Olschowsky' 'Tobias Sippel' 'Nico Elvedi' 'Ko Itakura'\n",
      " 'Marvin Friedrich' 'Tony Jantschke' 'Mamadou Doucouré' 'Ramy Bensebaini'\n",
      " 'Luca Netz' 'Joe Scally' 'Stefan Lainer' 'Simon Walde' 'Julian Weigl'\n",
      " 'Christoph Kramer' 'Manu Koné' 'Florian Neuhaus' 'Oscar Fraulo'\n",
      " 'Lars Stindl' 'Conor Noß' 'Alassane Plea' 'Hannes Wolf'\n",
      " 'Yvandro Borges Sanches' 'Jonas Hofmann' 'Nathan Ngoumou'\n",
      " 'Patrick Herrmann' 'Marcus Thuram' 'Koen Casteels' 'Pavao Pervan'\n",
      " 'Philipp Schulze' 'Niklas Klinger' 'Maxence Lacroix' 'Micky van de Ven'\n",
      " 'Sebastiaan Bornauw' 'Paulo Otávio' 'Nicolas Cozza' 'Ridle Baku'\n",
      " 'Kilian Fischer' 'Bartol Franjic' 'Josuha Guilavogui' 'Maximilian Arnold'\n",
      " 'Mattias Svanberg' 'Yannick Gerhardt' 'Kevin Paredes' 'Felix Nmecha'\n",
      " 'Jakub Kaminski' 'Patrick Wimmer' 'Luca Waldschmidt' 'Lukas Nmecha'\n",
      " 'Jonas Wind' 'Omar Marmoush' 'Dzenan Pejcinovic' 'Mark Flekken'\n",
      " 'Noah Atubolu' 'Benjamin Uphoff' 'Philipp Lienhart' 'Matthias Ginter'\n",
      " 'Manuel Gulde' 'Kenneth Schmidt' 'Christian Günter' 'Kimberly Ezekwem'\n",
      " 'Kiliann Sildillia' 'Lukas Kübler' 'Jonathan Schmid' 'Yannik Keitel'\n",
      " 'Nicolas Höfler' 'Maximilian Eggestein' 'Merlin Röhl' 'Robert Wagner'\n",
      " 'Daniel-Kofi Kyereh' 'Vincenzo Grifo' 'Noah Weißhaupt' 'Ritsu Doan'\n",
      " 'Roland Sallai' 'Woo-yeong Jeong' 'Michael Gregoritsch' 'Lucas Höler'\n",
      " 'Nils Petersen' 'Oliver Baumann' 'Philipp Pentke' 'Luca Philipp'\n",
      " 'Nahuel Noll' 'Ozan Kabak' 'Stanley Nsoki' 'Kevin Akpoguma' 'Kevin Vogt'\n",
      " 'John Anthony Brooks' 'Eduardo Quaresma' 'Ermin Bicakcic' 'Angeliño'\n",
      " 'Pavel Kaderabek' 'Justin Che' 'Angelo Stiller' 'Sebastian Rudy'\n",
      " 'Dennis Geiger' 'Grischa Prömel' 'Thomas Delaney' 'Finn Ole Becker'\n",
      " 'Umut Tohumcu' 'Robert Skov' 'Christoph Baumgartner' 'Tom Bischof'\n",
      " 'Muhammed Damar' 'Jacob Bruun Larsen' 'Kasper Dolberg' 'Andrej Kramaric'\n",
      " 'Ihlas Bebou' 'Munas Dabbur' 'Fisnik Asllani' 'Frederik Rönnow'\n",
      " 'Lennart Grill' 'Jakob Busk' 'Diogo Leite' 'Danilho Doekhi'\n",
      " 'Paul Jaeckel' 'Robin Knoche' 'Timo Baumgartl' 'Jérôme Roussillon'\n",
      " 'Niko Gießelmann' 'Josip Juranovic' 'Christopher Trimmel' 'Rani Khedira'\n",
      " 'Morten Thorsby' 'Janik Haberer' 'András Schäfer' 'Aïssa Laïdouni'\n",
      " 'Paul Seguin' 'Levin Öztunali' 'Kevin Möhwald' 'Milos Pantovic'\n",
      " 'Tim Maciejewski' 'Sheraldo Becker' 'Jamie Leweling' 'Jordan'\n",
      " 'Kevin Behrens' 'Sven Michel' 'Rafal Gikiewicz' 'Tomas Koubek'\n",
      " 'Daniel Klein' 'Benjamin Leneis' 'Felix Uduokhai' 'Reece Oxford'\n",
      " 'Jeffrey Gouweleeuw' 'Maximilian Bauer' 'Iago' 'Mads Pedersen'\n",
      " 'David Colina' 'Aaron Zehnter' 'Robert Gumny' 'Niklas Dorsch'\n",
      " 'Renato Veiga' 'Tobias Strobl' 'Julian Baumgartlinger' 'Arne Maier'\n",
      " 'Elvis Rexhbecaj' 'Arne Engels' 'Fredrik Jensen' 'Mert Kömür'\n",
      " 'Rubén Vargas' 'Nathanaël Mbuku' 'André Hahn' 'Noah Joel Sarenren Bazee'\n",
      " 'Daniel Caligiuri' 'Ermedin Demirovic' 'Mergim Berisha' 'Dion Beljo'\n",
      " 'Kelvin Yeboah' 'Irvin Cardona' 'Florian Müller' 'Fabian Bredlow'\n",
      " 'Florian Schock' 'Konstantinos Mavropanos' 'Hiroki Ito' 'Waldemar Anton'\n",
      " 'Dan-Axel Zagadou' 'Antonis Aidonis' 'Borna Sosa' 'Josha Vagnoman'\n",
      " 'Pascal Stenzel' 'Wataru Endo' 'Atakan Karazor' 'Enzo Millot'\n",
      " 'Nikolas Nartey' 'Genki Haraguchi' 'Lilian Egloff' 'Ömer Beyaz'\n",
      " 'Laurin Ulrich' 'Silas' 'Chris Führich' 'Tanguy Coulibaly' 'Gil Dias'\n",
      " 'Serhou Guirassy' 'Tiago Tomás' 'Juan José Perea' 'Luca Pfeiffer'\n",
      " 'Thomas Kastanaras' 'Alou Kuol' 'Robin Zentner' 'Finn Dahmen'\n",
      " 'Lasse Rieß' 'Maxim Leitsch' 'Andreas Hanche-Olsen' 'Stefan Bell'\n",
      " 'Alexander Hack' 'Philipp Schulz' 'Anthony Caci' 'Aarón Martín'\n",
      " 'Silvan Widmer' 'Danny da Costa' 'Anton Stach' 'Leandro Barreiro'\n",
      " 'Dominik Kohr' 'Edimilson Fernandes' 'Aymen Barkok' 'Eniss Shabani'\n",
      " 'Jae-sung Lee' 'Delano Burgzorg' 'Brajan Gruda' 'Jonathan Burkardt'\n",
      " 'Ludovic Ajorque' 'Marcus Ingvartsen' 'Karim Onisiwo' 'Nelson Weiper'\n",
      " 'Marlon Mustapha' 'Marvin Schwäbe' 'Timo Horn' 'Julian Roloff'\n",
      " 'Matthias Köbbing' 'Timo Hübers' 'Luca Kilian' 'Julian Chabot'\n",
      " 'Nikola Soldo' 'Rijad Smajic' 'Elias Bakatukanda' 'Jonas Hector'\n",
      " 'Kristian Pedersen' 'Benno Schmitz' 'Ellyes Skhiri' 'Dejan Ljubicic'\n",
      " 'Eric Martel' 'Georg Strauch' 'Denis Huseinbasic' 'Mathias Olesen'\n",
      " 'Joshua Schwirten' 'Kingsley Schindler' 'Florian Kainz' 'Jan Thielmann'\n",
      " 'Linton Maina' 'Dimitrios Limnios' 'Steffen Tigges' 'Mark Uth'\n",
      " 'Sargis Adamyan' 'Tim Lemperle' 'Davie Selke' 'Sebastian Andersson'\n",
      " 'Florian Dietz' 'Maximilian Schmid' 'Oliver Christensen' 'Tjark Ernst'\n",
      " 'Rune Jarstein' 'Marc Oliver Kempf' 'Márton Dárdai' 'Agustín Rogel'\n",
      " 'Filip Uremovic' 'Maximilian Mittelstädt' 'Marvin Plattenhardt'\n",
      " 'Lukas Ullrich' 'Jonjoe Kenny' 'Peter Pekarik' 'Julian Eitschberger'\n",
      " 'Lucas Tousart' 'Ivan Sunjic' 'Tolga Cigerci' 'Suat Serdar'\n",
      " 'Jean-Paul Boëtius' 'Kevin-Prince Boateng' 'Chidera Ejuke'\n",
      " 'Dodi Lukébakio' 'Marco Richter' 'Kelian Nsona' 'Jessic Ngankam'\n",
      " 'Wilfried Kanga' 'Florian Niederlechner' 'Stevan Jovetic'\n",
      " 'Derry Scherhant' 'Ibrahim Maza' 'Jiri Pavlenka' 'Michael Zetterer'\n",
      " 'Mio Backhaus' 'Dudu' 'Louis Lord' 'Marco Friedl' 'Amos Pieper'\n",
      " 'Niklas Stark' 'Milos Veljkovic' 'Fabio Chiarodia' 'Lee Buchanan'\n",
      " 'Anthony Jung' 'Mitchell Weiser' 'Felix Agu' 'Ilia Gruev'\n",
      " 'Christian Groß' 'Dikeni Salifou' 'Jens Stage' 'Jean Manuel Mbom'\n",
      " 'Romano Schmid' 'Leonardo Bittencourt' 'Niklas Schmidt'\n",
      " 'Maximilian Philipp' 'Niclas Füllkrug' 'Marvin Ducksch' 'Eren Dinkci'\n",
      " 'Alexander Schwolow' 'Ralf Fährmann' 'Justin Heekeren' 'Michael Langer'\n",
      " 'Moritz Jenz' 'Sepp van den Berg' 'Leo Greiml' 'Maya Yoshida'\n",
      " 'Marcin Kaminski' 'Henning Matriciani' 'Timothée Kolodziejczak'\n",
      " 'Ibrahima Cissé' 'Thomas Ouwejan' 'Jere Uronen' 'Cédric Brunner'\n",
      " 'Mehmet Aydin' 'Alex Kral' 'Éder Balanta' 'Niklas Tauer' 'Tom Krauß'\n",
      " 'Danny Latza' 'Soichiro Kozuki' 'Tobias Mohr' 'Rodrigo Zalazar'\n",
      " 'Dominick Drexler' 'Marius Bülter' 'Tim Skarke' 'Michael Frey'\n",
      " 'Sebastian Polter' 'Kenan Karaman' 'Simon Terodde' 'Manuel Riemann'\n",
      " 'Marko Johansson' 'Michael Esser' 'Paul Grave' 'Erhan Masovic'\n",
      " 'Ivan Ordets' 'Keven Schlotterbeck' 'Dominique Heintz'\n",
      " 'Vasilios Lampropoulos' 'Mohammed Tolba' 'Danilo Soares'\n",
      " 'Konstantinos Stafylidis' 'Jordi Osei-Tutu' 'Saidy Janko'\n",
      " 'Cristian Gamboa' 'Jacek Goralski' 'Anthony Losilla' 'Patrick Osterhage'\n",
      " 'Pierre Kunde' 'Kevin Stöger' 'Philipp Förster' 'Gerrit Holtmann'\n",
      " 'Christopher Antwi-Adjei' 'Takuma Asano' 'Philipp Hofmann' 'Simon Zoller'\n",
      " 'Silvère Ganvoula' 'Moritz Broschinski']\n"
     ]
    }
   ],
   "source": [
    "print(biomechanical_data['Subject'].unique())\n",
    "print(player_stats['name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping should be verified or updated\n",
    "subject_to_name = {\n",
    "    '1': 'manuel neuer',\n",
    "    '2': 'yann sommer',\n",
    "    '3': 'sven ulreich',\n",
    "    '4': 'johannes schenk',\n",
    "    # Update mappings if necessary\n",
    "}\n",
    "\n",
    "biomechanical_data['name'] = biomechanical_data['Subject'].map(subject_to_name).str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      0\n",
      "name            0\n",
      "full_name       0\n",
      "age             0\n",
      "height          0\n",
      "             ... \n",
      "RHIPEXT       515\n",
      "LHIPEXT       515\n",
      "RHIPER        515\n",
      "LHIPER        515\n",
      "RHIPIR        515\n",
      "Length: 67, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Neethiarasu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(data):\n",
    "    # For numerical columns, fill NaNs with the median value\n",
    "    numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        median_value = data[column].median()\n",
    "        data[column] = data[column].fillna(median_value)\n",
    "    \n",
    "    # For categorical columns, fill NaNs with the mode value\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if not data[column].mode().empty:\n",
    "            mode_value = data[column].mode()[0]\n",
    "        else:\n",
    "            mode_value = 'Unknown'\n",
    "        data[column] = data[column].fillna(mode_value)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "merged_data_filled = fill_missing_values(merged_data)\n",
    "\n",
    "# Verify that missing values have been handled\n",
    "print(merged_data_filled.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Subject' is entirely NaN; filling with 0.\n",
      "Column 'Age' is entirely NaN; filling with 0.\n",
      "Column 'Height' is entirely NaN; filling with 0.\n",
      "Column 'Mass' is entirely NaN; filling with 0.\n",
      "Column 'Experience' is entirely NaN; filling with 0.\n",
      "Column 'SessionsPerWk' is entirely NaN; filling with 0.\n",
      "Column 'Treadmill' is entirely NaN; filling with 0.\n",
      "Column 'Aslphalt' is entirely NaN; filling with 0.\n",
      "Column 'Grass' is entirely NaN; filling with 0.\n",
      "Column 'Trail' is entirely NaN; filling with 0.\n",
      "Column 'Sand' is entirely NaN; filling with 0.\n",
      "Column 'Concrete' is entirely NaN; filling with 0.\n",
      "Column 'SurfaceAlt' is entirely NaN; filling with 0.\n",
      "Column 'Pace' is entirely NaN; filling with 0.\n",
      "Column 'ShoeSize' is entirely NaN; filling with 0.\n",
      "Column 'ShoePairs' is entirely NaN; filling with 0.\n",
      "Column 'ShoeComfort' is entirely NaN; filling with 0.\n",
      "Column 'RThomas' is entirely NaN; filling with 0.\n",
      "Column 'LThomas' is entirely NaN; filling with 0.\n",
      "Column 'ROber' is entirely NaN; filling with 0.\n",
      "Column 'LOber' is entirely NaN; filling with 0.\n",
      "Column 'RHIPABD' is entirely NaN; filling with 0.\n",
      "Column 'LHIPABD' is entirely NaN; filling with 0.\n",
      "Column 'RHIPEXT' is entirely NaN; filling with 0.\n",
      "Column 'LHIPEXT' is entirely NaN; filling with 0.\n",
      "Column 'RHIPER' is entirely NaN; filling with 0.\n",
      "Column 'LHIPER' is entirely NaN; filling with 0.\n",
      "Column 'RHIPIR' is entirely NaN; filling with 0.\n",
      "Unnamed: 0    0\n",
      "name          0\n",
      "full_name     0\n",
      "age           0\n",
      "height        0\n",
      "             ..\n",
      "RHIPEXT       0\n",
      "LHIPEXT       0\n",
      "RHIPER        0\n",
      "LHIPER        0\n",
      "RHIPIR        0\n",
      "Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(data):\n",
    "    # For numerical columns, fill NaNs with the median value\n",
    "    numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        if data[column].notna().any():  # Check if there are any non-NaN values\n",
    "            median_value = data[column].median()\n",
    "            data[column] = data[column].fillna(median_value)\n",
    "        else:\n",
    "            print(f\"Column '{column}' is entirely NaN; filling with 0.\")\n",
    "            data[column] = data[column].fillna(0)\n",
    "    \n",
    "    # For categorical columns, fill NaNs with the mode value\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if data[column].notna().any():  # Check if there are any non-NaN values\n",
    "            mode_value = data[column].mode()[0]\n",
    "            data[column] = data[column].fillna(mode_value)\n",
    "        else:\n",
    "            print(f\"Column '{column}' is entirely NaN; filling with 'Unknown'.\")\n",
    "            data[column] = data[column].fillna('Unknown')\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "merged_data_filled = fill_missing_values(merged_data)\n",
    "\n",
    "# Verify that missing values have been handled\n",
    "print(merged_data_filled.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "name          0\n",
      "full_name     0\n",
      "age           0\n",
      "height        0\n",
      "             ..\n",
      "RHIPEXT       0\n",
      "LHIPEXT       0\n",
      "RHIPER        0\n",
      "LHIPER        0\n",
      "RHIPIR        0\n",
      "Length: 67, dtype: int64\n",
      "Final data shape: (515, 67)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(data):\n",
    "    # For numerical columns, fill NaNs with the median value\n",
    "    numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        if data[column].notna().any():  # Check if there are any non-NaN values\n",
    "            median_value = data[column].median()\n",
    "            data[column] = data[column].fillna(median_value)\n",
    "        else:\n",
    "            print(f\"Column '{column}' is entirely NaN; filling with 0.\")\n",
    "            data[column] = data[column].fillna(0)\n",
    "    \n",
    "    # For categorical columns, fill NaNs with the mode value\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if data[column].notna().any():  # Check if there are any non-NaN values\n",
    "            mode_value = data[column].mode()[0]\n",
    "            data[column] = data[column].fillna(mode_value)\n",
    "        else:\n",
    "            print(f\"Column '{column}' is entirely NaN; filling with 'Unknown'.\")\n",
    "            data[column] = data[column].fillna('Unknown')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def drop_empty_columns(data):\n",
    "    \"\"\"Drop columns that are entirely NaN.\"\"\"\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    return data\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "merged_data_filled = fill_missing_values(merged_data)\n",
    "\n",
    "# Drop empty columns\n",
    "merged_data_cleaned = drop_empty_columns(merged_data_filled)\n",
    "\n",
    "# Verify the final dataset\n",
    "print(merged_data_cleaned.isnull().sum())\n",
    "print(f\"Final data shape: {merged_data_cleaned.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
